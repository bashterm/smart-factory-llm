import json

from copy        import copy
from collections import Counter
from math        import ceil

class Coordinator:

  def __init__(self, procedures, to_execute_filepath, workstations):

    # Store the procedures that the factory is running
    self.procedures = procedures

    # Get a map from each procedure id to the number of times that it has to be executed
    with open(to_execute_filepath) as file:
      to_execute = json.loads(file.read())

    self.required_processes = Counter()
    for procedure in procedures:
      self.required_processes += self.get_required_processes(procedure, to_execute[procedure.id])
    
    # Compute the set of processes that have not be assigned to any workstation or machine
    self.unassigned = copy(self.required_processes)

    # Store the workstations
    self.workstations = workstations
    
  # Find the multiset of processes that need to be run to execute a procedure 
  # num_executions times. Recall that no token in a procedure is generated by 
  # two different processes. 
  def get_required_processes(self, procedure, num_executions):

    required_processes = Counter()  # Process Id -> # of executions required
    required_tokens    = Counter()  # Token Id   -> # of tokens required

    # Initialize required tokens with num_execution copies of the token consumed by the
    # procedure's output function
    output_process_id = procedure.output_process
    output_process    = procedure.processes[output_process_id]
    required_tokens  += output_process.inputs

    # print(f"procedure:{procedure.id}")
    # print(f"required_tokens:{required_tokens}")

    # While there is an required token not generated:
    while any(required_tokens.values()):

      # Get a required token to generate
      token = next(tk for tk, num_required in required_tokens.items() if num_required)
      # print(f"token:{token}")

      # Find the process that generates the tokens
      p_id,process = next((p_id,p) for p_id,p in procedure.processes.items() if token in p.outputs)
      # print(f"process:{p_id}")

      # Work out how many times the process needs to be run
      required_executions = ceil(required_tokens[token] / process.outputs[token])
      # print(f"required_executions:{required_executions}")

      # Add the required tokens to execute the process required_executions times
      for _ in range(required_executions): required_tokens += process.inputs

      # Add the required executions of the process to required_processes
      required_processes[p_id] += required_executions

      # Remove the current required token from the counter
      del required_tokens[token]
      # print(f"required_tokens:{required_tokens}")
      # input(f"required_processes:{required_processes}")

    return required_processes


      


    


  # Gets the set of all processes in the procedures
  def get_all_processes(self):

    processes = {}

    for procedure in self.procedures:
      for pid, process in procedure.processes.items():

        # If processes already contains a process with pid, make sure that the two processes
        # are identical.
        if pid in processes:
          assert processes[pid] == process, (
            f"Two processes:\n"
            f"{process.to_str_with_pid(pid)}\n"
            f"{processes[pid].to_str_with_pid(pid)}\n"
            f"share the same pid but are not identical")

        # Otherwise, add the process to the dict
        else:
          processes[pid] = process

    return processes


  # Prints the procedures' processes
  def print_all_processes(self):
    processes = self.get_all_processes()
    for pid, process in processes.items():
      print(process.to_str_with_pid(pid))


  # Gets the set of all tokens in the procedures
  def get_all_tokens(self):
    return set().union(*[set(procedure.tokens) for procedure in self.procedures])


  # Prints the procedures' tokens
  def print_all_tokens(self):
    print(self.get_all_tokens())